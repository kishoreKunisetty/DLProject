{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrJg1hCC0eb9"
   },
   "source": [
    "#Lab - 13\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MUNAGALA SUSANK\n",
    "#19BCI7044\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JItNys5v0ecF"
   },
   "source": [
    "## Loading the Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7OXOAC8_0ecH"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vd3QCmqu0ecL"
   },
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling, read-binary\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jX1NjlJn0ecM"
   },
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5CtHDHj0ecN"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVu2btDg0ecO"
   },
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM-XVD6F0ecQ",
    "outputId": "cf08228f-db4c-4db7-dc48-7ebf313711ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBidYxpY0ecT",
    "outputId": "b73d36ef-4b12-4a47-bd44-2231167f3365"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZpRQErV0ecW",
    "outputId": "a1b0f075-1dc6-4095-942a-e0a107201ab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS46HrvJ0ecX",
    "outputId": "1b62c843-2080-47ad-b74c-d4dda718ff50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XY17uCz0ecY"
   },
   "source": [
    "- the train data contains 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Bt8MOjQ0ecZ",
    "outputId": "632c8531-5520-4a87-d113-13d26ce6e20f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Mary', 'in', 'the', 'bathroom', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xs_gOfC90eca",
    "outputId": "a13b3cb5-e303-48af-d55e-9e957fb5d6ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ltkc3JH0ecb",
    "outputId": "099bd8ba-d0f6-48bb-dd1c-d847577afce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Daniel grabbed the apple there.\n",
      "Daniel went to the bedroom.\n",
      "John moved to the garden.\n",
      "Sandra journeyed to the office.\n",
      "Daniel put down the apple.\n",
      "Mary went to the bedroom.\n",
      "Mary grabbed the apple there.\n",
      "Sandra went back to the garden.\n",
      "Mary went to the kitchen.\n",
      "Daniel went to the office.\n",
      "\n",
      "Question: Is Mary in the garden?\n",
      "\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "print('Story:')\n",
    "for sent in train_data[99]:\n",
    "    if sent!='yes' and sent!='no':\n",
    "        for word in sent:\n",
    "            if (word!='.'):\n",
    "                if (word!='?'):\n",
    "                    text+= word + ' '\n",
    "                else:\n",
    "                    print()\n",
    "                    print('Question:', text[:-1]+word)\n",
    "                    print()\n",
    "            else:\n",
    "                print(text[:-1]+word)\n",
    "                text=''\n",
    "    else:\n",
    "        print('Answer:', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vic7Iy0r0ecd"
   },
   "source": [
    "- list of tuples\n",
    "    - tuple contains: story x, question q and answer a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "chmT4P830ece",
    "outputId": "a2155237-e2f6-4b9d-d042-33b08ac318f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Ut0pmqj70ece",
    "outputId": "8f00a231-4868-4f7c-c664-844aaf12f5c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YTSP-1D20ecg",
    "outputId": "c4d9148e-d267-4e71-ebbd-2b6a84617b03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvdXjda70ecg"
   },
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DcKQ67A_0ech"
   },
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5E1mywtY0ech"
   },
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fH2HDZ3m0eci",
    "outputId": "84972a23-0711-4d1b-f25c-31a4a2d386be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wt3tJrx0ecj",
    "outputId": "6598ba1a-9e28-4c00-d0d7-08fca7f3d345"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0]) # story component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TYMDrV9r0ecj"
   },
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "003PQ_Zv0eck"
   },
   "source": [
    "- adding the answer possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w_Gtjo9o0eck"
   },
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrkL18zc0eck",
    "outputId": "62cfd523-db06-4642-b9f6-6a7a18bdbd13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VDD1oD2R0ecl"
   },
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 # we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIe0yzBv0ecl",
    "outputId": "ba165f5a-4f03-4c79-888d-27f4a38b7700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "J0XROAhi0ecm"
   },
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9Vc90AS0ecm",
    "outputId": "dccff930-8a60-4f57-b226-d0cb386f7f3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FXa6ejCV0ecm"
   },
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jS58yewW0ecn",
    "outputId": "fdbf281a-790f-4999-dade-27f63f400890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc-BqKfX0ecn"
   },
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RLwGZne50ecn"
   },
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUALwKuk0eco"
   },
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_iEvDZE80eco"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "v7drCXDm0ecp"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])   # provide empty list for filter out\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jExGpCFk0ecp",
    "outputId": "3b5dbb85-2a10-44b1-bd09-08a22e2bb189"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 31,\n",
       " '?': 29,\n",
       " 'apple': 36,\n",
       " 'back': 35,\n",
       " 'bathroom': 27,\n",
       " 'bedroom': 34,\n",
       " 'daniel': 4,\n",
       " 'discarded': 18,\n",
       " 'down': 12,\n",
       " 'dropped': 19,\n",
       " 'football': 7,\n",
       " 'garden': 11,\n",
       " 'got': 26,\n",
       " 'grabbed': 1,\n",
       " 'hallway': 33,\n",
       " 'in': 21,\n",
       " 'is': 16,\n",
       " 'john': 32,\n",
       " 'journeyed': 17,\n",
       " 'kitchen': 37,\n",
       " 'left': 9,\n",
       " 'mary': 20,\n",
       " 'milk': 28,\n",
       " 'moved': 30,\n",
       " 'no': 2,\n",
       " 'office': 10,\n",
       " 'picked': 5,\n",
       " 'put': 14,\n",
       " 'sandra': 22,\n",
       " 'the': 25,\n",
       " 'there': 3,\n",
       " 'to': 6,\n",
       " 'took': 8,\n",
       " 'travelled': 24,\n",
       " 'up': 13,\n",
       " 'went': 15,\n",
       " 'yes': 23}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8Gf3j9NU0ecq"
   },
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YhDoxdAc0ecq"
   },
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsqqWORz0ecq",
    "outputId": "225b9f32-987e-4df6-9bdd-2b4350adac72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sprM7J0i0ecr",
    "outputId": "f9556fd6-d424-4c87-e757-3a84a28cfcd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AFQM4u5r0ecr"
   },
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz-rWIGq0ecr"
   },
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lG4Br06L0ecs"
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(vocab_size)  # this includes +1 for padding\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "yvb1QzmC0ecs"
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XW5yW4rU0ect"
   },
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYAGjq020ect",
    "outputId": "e395b724-5fa3-4281-9498-deb8dac10691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 25, 34, 31],\n",
       "       [ 0,  0,  0, ..., 25, 11, 31],\n",
       "       [ 0,  0,  0, ..., 25, 11, 31],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 25, 36, 31],\n",
       "       [ 0,  0,  0, ..., 25, 11, 31],\n",
       "       [ 0,  0,  0, ..., 36,  3, 31]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding mode 'pre'\n",
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMFITUYJ0ect",
    "outputId": "81e68e8c-27be-4818-c1e2-3fb75a554aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 32, 21, 25, 37, 29],\n",
       "       [16, 32, 21, 25, 37, 29],\n",
       "       [16, 32, 21, 25, 11, 29],\n",
       "       ...,\n",
       "       [16, 20, 21, 25, 34, 29],\n",
       "       [16, 22, 21, 25, 11, 29],\n",
       "       [16, 20, 21, 25, 11, 29]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RPQNIhI0ecu",
    "outputId": "aae4eba9-0668-44a1-d84e-0848b56af53d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot vectors of size V vocabulary for Yes / No\n",
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXdNaCcp0ecu",
    "outputId": "574e21d9-4c3c-41ff-b76c-bc4146d3088c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal proportion of Yes / No answers\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AA4ZFLHG0ecu",
    "outputId": "104cff9c-c429-4c9b-b426-df648512f5e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zu3Bqca0ecv",
    "outputId": "a7bbe87e-72e5-4721-8cf7-f6118b31c5d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjZ8_uU50ecv"
   },
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "6Ptufaqf0ecw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj_UmiEE0ecw"
   },
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KpaPgJpG0ecx"
   },
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF4X54ZB0ecx"
   },
   "source": [
    "### Building the Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8BHWdPp0ecy"
   },
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "TAYtA6hL0ecy"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim= embedding_dim))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xY3HFgd0ecy"
   },
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "6rpLbRzl0ecz"
   },
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viweNsCt0ecz"
   },
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "m_laDXmC0ec0"
   },
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpLbTQ6W0ec0"
   },
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "JdcN6Czf0ec0"
   },
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices) to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdD8cfAd0ec1"
   },
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "pC1lQ37_0ec1"
   },
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDwCtHg10ec1"
   },
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "sDnj0Xd80ec2"
   },
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0yL1q7q0ec2"
   },
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "SlOlAhux0ec3"
   },
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "# (samples, query_maxlen, story_maxlen + embedding_dim)\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFsmkMQy0ec3",
    "outputId": "a424f802-2537-4e69-bfac-6685b7eb1425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 284) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "99VcexsY0ec3"
   },
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # shape (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "c9am4fHc0ec4"
   },
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "5m8wUiBs0ec4"
   },
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2L5Yirg0ec5",
    "outputId": "0ea52ffd-9131-455b-8ae9-e123014c71fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 128)    4864        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 128)       4864        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 284)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           40576       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,786\n",
      "Trainable params: 51,786\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "nzHuWTCK0ec5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "epochs = 120\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 20\n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.66, patience=5, min_lr=0.0001, verbose=1)  # factor by which the learning rate will be reduced. new_lr = lr * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0f8wfNV0ec6",
    "outputId": "40e15211-98cf-48f0-8c29-1898cc4eab15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "40/40 [==============================] - 9s 140ms/step - loss: 0.8645 - accuracy: 0.4840 - val_loss: 0.7014 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.7058 - accuracy: 0.4979 - val_loss: 0.7940 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.7056 - accuracy: 0.4938 - val_loss: 0.7585 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.7011 - accuracy: 0.4996 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.6984 - accuracy: 0.5004 - val_loss: 0.7339 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.6988 - accuracy: 0.4920 - val_loss: 0.6962 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.6873 - accuracy: 0.5295 - val_loss: 0.9981 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.5156 - accuracy: 0.7616 - val_loss: 0.4396 - val_accuracy: 0.8330\n",
      "Epoch 9/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.3967 - accuracy: 0.8355 - val_loss: 0.5300 - val_accuracy: 0.8150\n",
      "Epoch 10/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.3647 - accuracy: 0.8488 - val_loss: 0.4360 - val_accuracy: 0.7780\n",
      "Epoch 11/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.3663 - accuracy: 0.8388 - val_loss: 0.4026 - val_accuracy: 0.8310\n",
      "Epoch 12/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.3342 - accuracy: 0.8556 - val_loss: 0.3723 - val_accuracy: 0.8300\n",
      "Epoch 13/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.3322 - accuracy: 0.8541 - val_loss: 0.3515 - val_accuracy: 0.8350\n",
      "Epoch 14/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.3193 - accuracy: 0.8561 - val_loss: 0.3879 - val_accuracy: 0.8300\n",
      "Epoch 15/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.3099 - accuracy: 0.8583 - val_loss: 0.3730 - val_accuracy: 0.8350\n",
      "Epoch 16/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.3090 - accuracy: 0.8582 - val_loss: 0.3397 - val_accuracy: 0.8370\n",
      "Epoch 17/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.3033 - accuracy: 0.8624 - val_loss: 0.3881 - val_accuracy: 0.8360\n",
      "Epoch 18/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2987 - accuracy: 0.8660 - val_loss: 0.3664 - val_accuracy: 0.8330\n",
      "Epoch 19/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2973 - accuracy: 0.8642 - val_loss: 0.4379 - val_accuracy: 0.8190\n",
      "Epoch 20/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2947 - accuracy: 0.8655 - val_loss: 0.3754 - val_accuracy: 0.8330\n",
      "Epoch 21/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2863 - accuracy: 0.8729 - val_loss: 0.3675 - val_accuracy: 0.8250\n",
      "Epoch 22/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2868 - accuracy: 0.8683 - val_loss: 0.3479 - val_accuracy: 0.8340\n",
      "Epoch 23/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2850 - accuracy: 0.8698 - val_loss: 0.3569 - val_accuracy: 0.8450\n",
      "Epoch 24/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2772 - accuracy: 0.8732 - val_loss: 0.3954 - val_accuracy: 0.8100\n",
      "Epoch 25/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2752 - accuracy: 0.8728 - val_loss: 0.3563 - val_accuracy: 0.8330\n",
      "Epoch 26/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.2697 - accuracy: 0.8762 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
      "Epoch 27/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2595 - accuracy: 0.8842 - val_loss: 0.5356 - val_accuracy: 0.7690\n",
      "Epoch 28/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2602 - accuracy: 0.8867 - val_loss: 0.4446 - val_accuracy: 0.8260\n",
      "Epoch 29/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2504 - accuracy: 0.8890 - val_loss: 0.3984 - val_accuracy: 0.8460\n",
      "Epoch 30/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2300 - accuracy: 0.8964 - val_loss: 0.3915 - val_accuracy: 0.8490\n",
      "Epoch 31/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2241 - accuracy: 0.8985 - val_loss: 0.3348 - val_accuracy: 0.8570\n",
      "Epoch 32/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2098 - accuracy: 0.9061 - val_loss: 0.4232 - val_accuracy: 0.8430\n",
      "Epoch 33/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.2079 - accuracy: 0.9097 - val_loss: 0.3171 - val_accuracy: 0.8670\n",
      "Epoch 34/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1887 - accuracy: 0.9185 - val_loss: 0.3203 - val_accuracy: 0.8660\n",
      "Epoch 35/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1713 - accuracy: 0.9273 - val_loss: 0.2856 - val_accuracy: 0.8880\n",
      "Epoch 36/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1612 - accuracy: 0.9306 - val_loss: 0.2732 - val_accuracy: 0.8670\n",
      "Epoch 37/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1548 - accuracy: 0.9327 - val_loss: 0.2438 - val_accuracy: 0.8970\n",
      "Epoch 38/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1473 - accuracy: 0.9371 - val_loss: 0.2654 - val_accuracy: 0.8990\n",
      "Epoch 39/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1445 - accuracy: 0.9413 - val_loss: 0.2440 - val_accuracy: 0.9030\n",
      "Epoch 40/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1300 - accuracy: 0.9452 - val_loss: 0.2522 - val_accuracy: 0.9020\n",
      "Epoch 41/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.1302 - accuracy: 0.9450 - val_loss: 0.2652 - val_accuracy: 0.9090\n",
      "Epoch 42/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.1244 - accuracy: 0.9488 - val_loss: 0.2813 - val_accuracy: 0.9050\n",
      "Epoch 43/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1224 - accuracy: 0.9479 - val_loss: 0.2613 - val_accuracy: 0.8950\n",
      "Epoch 44/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1141 - accuracy: 0.9535 - val_loss: 0.2382 - val_accuracy: 0.9120\n",
      "Epoch 45/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1086 - accuracy: 0.9554 - val_loss: 0.2749 - val_accuracy: 0.9210\n",
      "Epoch 46/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1103 - accuracy: 0.9559 - val_loss: 0.2848 - val_accuracy: 0.9240\n",
      "Epoch 47/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0951 - accuracy: 0.9623 - val_loss: 0.2891 - val_accuracy: 0.9200\n",
      "Epoch 48/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0953 - accuracy: 0.9620 - val_loss: 0.2966 - val_accuracy: 0.9250\n",
      "Epoch 49/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0887 - accuracy: 0.9656 - val_loss: 0.3361 - val_accuracy: 0.9130\n",
      "Epoch 50/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0839 - accuracy: 0.9664 - val_loss: 0.2378 - val_accuracy: 0.9250\n",
      "Epoch 51/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0831 - accuracy: 0.9656 - val_loss: 0.2870 - val_accuracy: 0.9260\n",
      "Epoch 52/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0812 - accuracy: 0.9693 - val_loss: 0.2632 - val_accuracy: 0.9290\n",
      "Epoch 53/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0764 - accuracy: 0.9720 - val_loss: 0.2849 - val_accuracy: 0.9120\n",
      "Epoch 54/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0763 - accuracy: 0.9674 - val_loss: 0.2237 - val_accuracy: 0.9160\n",
      "Epoch 55/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0696 - accuracy: 0.9738 - val_loss: 0.3078 - val_accuracy: 0.9290\n",
      "Epoch 56/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0663 - accuracy: 0.9738 - val_loss: 0.2668 - val_accuracy: 0.9310\n",
      "Epoch 57/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 0.2897 - val_accuracy: 0.9320\n",
      "Epoch 58/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0645 - accuracy: 0.9750 - val_loss: 0.2966 - val_accuracy: 0.9220\n",
      "Epoch 59/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 0.2767 - val_accuracy: 0.9330\n",
      "Epoch 60/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0542 - accuracy: 0.9784 - val_loss: 0.2755 - val_accuracy: 0.9290\n",
      "Epoch 61/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.3485 - val_accuracy: 0.9230\n",
      "Epoch 62/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0546 - accuracy: 0.9805 - val_loss: 0.3169 - val_accuracy: 0.9280\n",
      "Epoch 63/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.2721 - val_accuracy: 0.9260\n",
      "Epoch 64/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0502 - accuracy: 0.9808 - val_loss: 0.2672 - val_accuracy: 0.9380\n",
      "Epoch 65/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 0.2806 - val_accuracy: 0.9310\n",
      "Epoch 66/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.2967 - val_accuracy: 0.9300\n",
      "Epoch 67/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.2428 - val_accuracy: 0.9230\n",
      "Epoch 68/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.2676 - val_accuracy: 0.9300\n",
      "Epoch 69/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0423 - accuracy: 0.9847 - val_loss: 0.3511 - val_accuracy: 0.9300\n",
      "Epoch 70/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0518 - accuracy: 0.9818 - val_loss: 0.2637 - val_accuracy: 0.9330\n",
      "Epoch 71/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0436 - accuracy: 0.9839 - val_loss: 0.4489 - val_accuracy: 0.9170\n",
      "Epoch 72/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.2928 - val_accuracy: 0.9300\n",
      "Epoch 73/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.3119 - val_accuracy: 0.9390\n",
      "Epoch 74/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 0.3180 - val_accuracy: 0.9270\n",
      "Epoch 75/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.2715 - val_accuracy: 0.9380\n",
      "Epoch 76/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.2633 - val_accuracy: 0.9350\n",
      "Epoch 77/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.2601 - val_accuracy: 0.9310\n",
      "Epoch 78/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0348 - accuracy: 0.9880 - val_loss: 0.2987 - val_accuracy: 0.9340\n",
      "Epoch 79/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.3059 - val_accuracy: 0.9280\n",
      "Epoch 80/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.2868 - val_accuracy: 0.9330\n",
      "Epoch 81/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0372 - accuracy: 0.9858 - val_loss: 0.2482 - val_accuracy: 0.9370\n",
      "Epoch 82/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.3508 - val_accuracy: 0.9280\n",
      "Epoch 83/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0305 - accuracy: 0.9892 - val_loss: 0.3378 - val_accuracy: 0.9420\n",
      "Epoch 84/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.3582 - val_accuracy: 0.9380\n",
      "Epoch 85/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0355 - accuracy: 0.9873 - val_loss: 0.2864 - val_accuracy: 0.9400\n",
      "Epoch 86/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 0.3264 - val_accuracy: 0.9380\n",
      "Epoch 87/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.2410 - val_accuracy: 0.9450\n",
      "Epoch 88/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.3345 - val_accuracy: 0.9370\n",
      "Epoch 89/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.2995 - val_accuracy: 0.9390\n",
      "Epoch 90/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 0.3222 - val_accuracy: 0.9340\n",
      "Epoch 91/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.3302 - val_accuracy: 0.9360\n",
      "Epoch 92/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.2994 - val_accuracy: 0.9250\n",
      "Epoch 93/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.2481 - val_accuracy: 0.9420\n",
      "Epoch 94/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.2722 - val_accuracy: 0.9410\n",
      "Epoch 95/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.3636 - val_accuracy: 0.9380\n",
      "Epoch 96/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.2705 - val_accuracy: 0.9520\n",
      "Epoch 97/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.2612 - val_accuracy: 0.9460\n",
      "Epoch 98/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.3277 - val_accuracy: 0.9410\n",
      "Epoch 99/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.2746 - val_accuracy: 0.9420\n",
      "Epoch 100/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.2775 - val_accuracy: 0.9510\n",
      "Epoch 101/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.2896 - val_accuracy: 0.9470\n",
      "Epoch 102/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.2697 - val_accuracy: 0.9470\n",
      "Epoch 103/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.3094 - val_accuracy: 0.9410\n",
      "Epoch 104/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.2791 - val_accuracy: 0.9470\n",
      "Epoch 105/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.2443 - val_accuracy: 0.9490\n",
      "Epoch 106/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.2593 - val_accuracy: 0.9490\n",
      "Epoch 107/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.2604 - val_accuracy: 0.9470\n",
      "Epoch 108/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.2375 - val_accuracy: 0.9510\n",
      "Epoch 109/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.3389 - val_accuracy: 0.9490\n",
      "Epoch 110/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.2452 - val_accuracy: 0.9510\n",
      "Epoch 111/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.2552 - val_accuracy: 0.9540\n",
      "Epoch 112/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.2544 - val_accuracy: 0.9470\n",
      "Epoch 113/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.2946 - val_accuracy: 0.9440\n",
      "Epoch 114/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.3411 - val_accuracy: 0.9410\n",
      "Epoch 115/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.3101 - val_accuracy: 0.9470\n",
      "Epoch 116/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.2510 - val_accuracy: 0.9500\n",
      "Epoch 117/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.2665 - val_accuracy: 0.9430\n",
      "Epoch 118/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.2522 - val_accuracy: 0.9520\n",
      "Epoch 119/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.2877 - val_accuracy: 0.9490\n",
      "Epoch 120/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.3429 - val_accuracy: 0.9450\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=256,epochs=120,validation_data=([inputs_test, queries_test], answers_test))  # , callbacks=[reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U78FawZb0ec6"
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmykQL4n0ec7",
    "outputId": "386d9ea1-1a1a-4d7c-f8aa-ff64c714ff63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "filename = 'chatbot_120_epochs_9710_susank.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-P0rQ640ec7"
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "PsTiuTUn0ec7",
    "outputId": "6622fedb-efef-4f8a-cb5a-7e93c7c124ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('accuracy.png', dpi=180, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkmsRJuQ0ec8"
   },
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "9_fvz3hk0ec8"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JVqWgzD0ec9",
    "outputId": "f3517101-5183-47a1-d3b4-80671263169e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghdFha0h0ec9",
    "outputId": "ca77bb2d-b49d-485f-9a62-906aa27d2850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWW6S8vH0ec-",
    "outputId": "4212ae62-9f27-486d-cef8-fc34cc3fb990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxyY9aYS0ec-",
    "outputId": "b1e63449-4a2e-4b99-9f44-9d95df30c070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXbc76N-0ec_",
    "outputId": "cf069dfc-dbe0-4153-c242-e3a13625d4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999995\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drZyjE1e0ec_"
   },
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSo3iB7k0edA",
    "outputId": "1cbe9c78-3bd9-4331-d5a8-0755bcf38a8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyI3o-cd0edA",
    "outputId": "c3e99589-2242-4ae7-e881-2b0b14067851"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "sPavwc1a0edB"
   },
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT75aB7R0edB",
    "outputId": "f00d35e9-426f-4111-d7ca-c993e5887f58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "B5w3WXcw0edB"
   },
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "6gemrd7U0edB"
   },
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "9dORqnm90edC"
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHS6axza0edC",
    "outputId": "84330d28-2aa5-4d79-df45-cfbedb426663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9999734\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4G23qlZ0edC"
   },
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ZpCrSt5C0edD"
   },
   "outputs": [],
   "source": [
    "my_story = \"Sandra grabbed Mary in the kitchen . Sandra picked the apple in the garden . John got back in the office . Mary got the milk . Daniel discarded the apple .\"\n",
    "my_question = \"Is apple in the garden ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "CvYfjDwI0edD"
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_d31wDu0edD",
    "outputId": "03eb7b10-11e7-4599-a52a-ff24ab89e741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.990622\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "R7YuM2Jw0edE"
   },
   "outputs": [],
   "source": [
    "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
    "my_question = \"Is Mary in the kitchen ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "HgdtBuB30edE"
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Azj-Kmzj0edE",
    "outputId": "bdfa38e2-eb53-4635-8405-6fa05a8aa673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9999995\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "J6ZpJsmm0edF"
   },
   "outputs": [],
   "source": [
    "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
    "my_question = \"Is Mary in the bedroom ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'no')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "fpC-z1E90edF"
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH35c8bb0edF",
    "outputId": "0f663549-9ce0-462c-dea4-75e0e29567c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999938\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "ji6z69sI0edG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_13_19BCI7044.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
